{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+0.5\">Notebook for transform data format to train the model<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Data transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp form in init data have this format\n",
    "form = \"%d/%m/%Y %H:%M:%S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to replace events\n",
    "replacement = {\"curva_direita_agressiva\": \"Aggressive right turn\",\n",
    "               \"curva_esquerda_agressiva\": \"Aggressive left turn\",\n",
    "               \"evento_nao_agressivo\": \"Non-aggressive event\",\n",
    "               \"troca_faixa_direita_agressiva\": \"Aggressive right lane change\",\n",
    "               \"aceleracao_agressiva\": \"Aggressive acceleration\",\n",
    "               \"freada_agressiva\": \"Aggressive breaking\",\n",
    "               \"troca_faixa_esquerda_agressiva\": \"Aggressive left lane change\",\n",
    "               \"No label\": \"No label\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to replace events\n",
    "def replace_event(row):\n",
    "    return replacement[row['event']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and concatenate accelerometer data with its events\n",
    "def make_labeled_data(folder_num):\n",
    "    # Load events and its time\n",
    "    data_label = pd.read_csv(os.path.join('data', 'data_init', str(folder_num), 'groundTruth.csv'))\n",
    "    # Load accelerometer data\n",
    "    data = pd.read_csv(os.path.join('data', 'data_init', str(folder_num), 'aceleracaoLinear_terra.csv'))\n",
    "    \n",
    "    # Take first time as start of the trip\n",
    "    init = datetime.strptime(data.loc[0]['timestamp'], form)\n",
    "    \n",
    "    # Function for changing time on its duration of the time by this trip to this record\n",
    "    def change_timestamp(row):\n",
    "        return (datetime.strptime(row['timestamp'], form) - init).seconds\n",
    "    \n",
    "    data = data.rename(columns={\"x\": \"x_accelerometer\", \"y\": \"y_accelerometer\", \"z\": \"z_accelerometer\"})\n",
    "    \n",
    "    data['time_duration'] = data.apply(change_timestamp, axis=1)\n",
    "    \n",
    "    for index, row in data_label.iterrows():\n",
    "        start = row[' inicio']\n",
    "        finish = row[' fim']\n",
    "        data.loc[((data['time_duration'] >= start) & (data['time_duration'] < finish)), 'event'] = row['evento']\n",
    "    \n",
    "    data['event'] = data['event'].fillna(\"No label\")\n",
    "    data['event'] = data.apply(replace_event, axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating sequence of events in one dataframe\n",
    "# Each event has its own number if it is on different time interval\n",
    "def create_events_sequence(data):\n",
    "    event_num = 1\n",
    "    event = data.iloc[0][\"event\"]\n",
    "    sequence = []\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        if row[\"event\"] != event:\n",
    "            event_num += 1\n",
    "            event = data.loc[index, \"event\"]\n",
    "        sequence.append(event_num)\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for adding new events to the dictionary of events\n",
    "def add_events_to_dict(data, dictionary):\n",
    "    # Create events sequence in this dataframe\n",
    "    data[\"event_number\"] = create_events_sequence(data)\n",
    "    # Select only labeled data\n",
    "    data = data[data[\"event\"] != \"No label\"]\n",
    "    # Group data by unique number of event\n",
    "    data_groupbed = data.groupby(\"event_number\")\n",
    "    \n",
    "    # For each unique event number\n",
    "    for group in np.unique(data[\"event_number\"].values):\n",
    "        current_group = data_groupbed.get_group(group)\n",
    "        event_name = current_group[\"event\"].values[0]\n",
    "        # If dictionary has this event name add dataframe to the list\n",
    "        # Otherwise create list with this dataframe\n",
    "        if dictionary.get(event_name):\n",
    "            dictionary[event_name].append(current_group)\n",
    "        else:\n",
    "            dictionary[event_name] = [current_group]\n",
    "    # Return updated dictionary\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = make_labeled_data(16)\n",
    "data2 = make_labeled_data(17)\n",
    "data3 = make_labeled_data(20)\n",
    "data4 = make_labeled_data(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Data filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Accelerometer data filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+0.5\">Look at both curves: initial and filtered and find those <i><b>window lenght</b></i> which filtered curva describe data in the best way.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_lengths = np.arange(11, 151, 10)\n",
    "polyorder = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for window_length in window_lengths:\n",
    "    \n",
    "    data1['x_accelerometer_fil'] = savgol_filter(data1['x_accelerometer'].values, window_length, polyorder)\n",
    "    data1['y_accelerometer_fil'] = savgol_filter(data1['y_accelerometer'].values, window_length, polyorder)\n",
    "    data1['z_accelerometer_fil'] = savgol_filter(data1['z_accelerometer'].values, window_length, polyorder)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "    \n",
    "    ax[0].plot(data1[:500]['x_accelerometer'].values, label='x accelerometer')\n",
    "    ax[0].plot(data1[:500]['x_accelerometer_fil'].values, label='x accelerometer filtered')\n",
    "    ax[0].legend();\n",
    "    \n",
    "    ax[1].plot(data1[:500]['y_accelerometer'].values, label='y accelerometer')\n",
    "    ax[1].plot(data1[:500]['y_accelerometer_fil'].values, label='y accelerometer filtered')\n",
    "    ax[1].legend();\n",
    "    \n",
    "    ax[2].plot(data1[:500]['z_accelerometer'].values, label='z accelerometer')\n",
    "    ax[2].plot(data1[:500]['z_accelerometer_fil'].values, label='z accelerometer filtered')\n",
    "    plt.suptitle(f\"Window length: {window_length}\", fontsize=20)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+0.5\">Look at both curves: initial and filtered and find those <i><b>polyorder</b></i> which filtered curve describe data in the best way.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyorders = np.arange(2, 15, 1)\n",
    "window_length = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for polyorder in polyorders:\n",
    "    \n",
    "    data1['x_accelerometer_fil'] = savgol_filter(data1['x_accelerometer'].values, window_length, polyorder)\n",
    "    data1['y_accelerometer_fil'] = savgol_filter(data1['y_accelerometer'].values, window_length, polyorder)\n",
    "    data1['z_accelerometer_fil'] = savgol_filter(data1['z_accelerometer'].values, window_length, polyorder)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "    \n",
    "    ax[0].plot(data1[:500]['x_accelerometer'].values, label='x accelerometer')\n",
    "    ax[0].plot(data1[:500]['x_accelerometer_fil'].values, label='x accelerometer filtered')\n",
    "    ax[0].legend();\n",
    "    \n",
    "    ax[1].plot(data1[:500]['y_accelerometer'].values, label='y accelerometer')\n",
    "    ax[1].plot(data1[:500]['y_accelerometer_fil'].values, label='y accelerometer filtered')\n",
    "    ax[1].legend();\n",
    "    \n",
    "    ax[2].plot(data1[:500]['z_accelerometer'].values, label='z accelerometer')\n",
    "    ax[2].plot(data1[:500]['z_accelerometer_fil'].values, label='z accelerometer filtered')\n",
    "    plt.suptitle(f\"Polyorder: {polyorder}\", fontsize=20)\n",
    "    ax[2].legend();\n",
    "    plt.show();\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyorder = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+0.5\">Use selected parameters for filtering accelerometer data.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['x_accelerometer_fil'] = savgol_filter(data1['x_accelerometer'].values, window_length, polyorder)\n",
    "data1['y_accelerometer_fil'] = savgol_filter(data1['y_accelerometer'].values, window_length, polyorder)\n",
    "data1['z_accelerometer_fil'] = savgol_filter(data1['z_accelerometer'].values, window_length, polyorder)\n",
    "\n",
    "data2['x_accelerometer_fil'] = savgol_filter(data2['x_accelerometer'].values, window_length, polyorder)\n",
    "data2['y_accelerometer_fil'] = savgol_filter(data2['y_accelerometer'].values, window_length, polyorder)\n",
    "data2['z_accelerometer_fil'] = savgol_filter(data2['z_accelerometer'].values, window_length, polyorder)\n",
    "\n",
    "data3['x_accelerometer_fil'] = savgol_filter(data3['x_accelerometer'].values, window_length, polyorder)\n",
    "data3['y_accelerometer_fil'] = savgol_filter(data3['y_accelerometer'].values, window_length, polyorder)\n",
    "data3['z_accelerometer_fil'] = savgol_filter(data3['z_accelerometer'].values, window_length, polyorder)\n",
    "\n",
    "data4['x_accelerometer_fil'] = savgol_filter(data4['x_accelerometer'].values, window_length, polyorder)\n",
    "data4['y_accelerometer_fil'] = savgol_filter(data4['y_accelerometer'].values, window_length, polyorder)\n",
    "data4['z_accelerometer_fil'] = savgol_filter(data4['z_accelerometer'].values, window_length, polyorder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Features creating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+0.5\">Create feature of mean, median, std and increase/decrease tendency of sliding window.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[\"mean_window_x_accelerometer\"] = data1[\"x_accelerometer_fil\"].rolling(8, min_periods=1).mean()\n",
    "data1[\"mean_window_y_accelerometer\"] = data1[\"y_accelerometer_fil\"].rolling(8, min_periods=1).mean()\n",
    "data1[\"mean_window_z_accelerometer\"] = data1[\"z_accelerometer_fil\"].rolling(8, min_periods=1).mean()\n",
    "\n",
    "data2[\"mean_window_x_accelerometer\"] = data2[\"x_accelerometer_fil\"].rolling(8, min_periods=1).mean()\n",
    "data2[\"mean_window_y_accelerometer\"] = data2[\"y_accelerometer_fil\"].rolling(8, min_periods=1).mean()\n",
    "data2[\"mean_window_z_accelerometer\"] = data2[\"z_accelerometer_fil\"].rolling(8, min_periods=1).mean()\n",
    "\n",
    "data3[\"mean_window_x_accelerometer\"] = data3[\"x_accelerometer_fil\"].rolling(8, min_periods=1).mean()\n",
    "data3[\"mean_window_y_accelerometer\"] = data3[\"y_accelerometer_fil\"].rolling(8, min_periods=1).mean()\n",
    "data3[\"mean_window_z_accelerometer\"] = data3[\"z_accelerometer_fil\"].rolling(8, min_periods=1).mean()\n",
    "\n",
    "data4[\"mean_window_x_accelerometer\"] = data4[\"x_accelerometer_fil\"].rolling(8, min_periods=1).mean()\n",
    "data4[\"mean_window_y_accelerometer\"] = data4[\"y_accelerometer_fil\"].rolling(8, min_periods=1).mean()\n",
    "data4[\"mean_window_z_accelerometer\"] = data4[\"z_accelerometer_fil\"].rolling(8, min_periods=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[\"std_window_x_accelerometer\"] = data1[\"x_accelerometer_fil\"].rolling(8, min_periods=1).std()\n",
    "data1[\"std_window_y_accelerometer\"] = data1[\"y_accelerometer_fil\"].rolling(8, min_periods=1).std()\n",
    "data1[\"std_window_z_accelerometer\"] = data1[\"z_accelerometer_fil\"].rolling(8, min_periods=1).std()\n",
    "\n",
    "data2[\"std_window_x_accelerometer\"] = data2[\"x_accelerometer_fil\"].rolling(8, min_periods=1).std()\n",
    "data2[\"std_window_y_accelerometer\"] = data2[\"y_accelerometer_fil\"].rolling(8, min_periods=1).std()\n",
    "data2[\"std_window_z_accelerometer\"] = data2[\"z_accelerometer_fil\"].rolling(8, min_periods=1).std()\n",
    "\n",
    "data3[\"std_window_x_accelerometer\"] = data3[\"x_accelerometer_fil\"].rolling(8, min_periods=1).std()\n",
    "data3[\"std_window_y_accelerometer\"] = data3[\"y_accelerometer_fil\"].rolling(8, min_periods=1).std()\n",
    "data3[\"std_window_z_accelerometer\"] = data3[\"z_accelerometer_fil\"].rolling(8, min_periods=1).std()\n",
    "\n",
    "data4[\"std_window_x_accelerometer\"] = data4[\"x_accelerometer_fil\"].rolling(8, min_periods=1).std()\n",
    "data4[\"std_window_y_accelerometer\"] = data4[\"y_accelerometer_fil\"].rolling(8, min_periods=1).std()\n",
    "data4[\"std_window_z_accelerometer\"] = data4[\"z_accelerometer_fil\"].rolling(8, min_periods=1).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[\"median_window_x_accelerometer\"] = data1[\"x_accelerometer_fil\"].rolling(8, min_periods=1).median()\n",
    "data1[\"median_window_y_accelerometer\"] = data1[\"y_accelerometer_fil\"].rolling(8, min_periods=1).median()\n",
    "data1[\"median_window_z_accelerometer\"] = data1[\"z_accelerometer_fil\"].rolling(8, min_periods=1).median()\n",
    "\n",
    "data2[\"median_window_x_accelerometer\"] = data2[\"x_accelerometer_fil\"].rolling(8, min_periods=1).median()\n",
    "data2[\"median_window_y_accelerometer\"] = data2[\"y_accelerometer_fil\"].rolling(8, min_periods=1).median()\n",
    "data2[\"median_window_z_accelerometer\"] = data2[\"z_accelerometer_fil\"].rolling(8, min_periods=1).median()\n",
    "\n",
    "data3[\"median_window_x_accelerometer\"] = data3[\"x_accelerometer_fil\"].rolling(8, min_periods=1).median()\n",
    "data3[\"median_window_y_accelerometer\"] = data3[\"y_accelerometer_fil\"].rolling(8, min_periods=1).median()\n",
    "data3[\"median_window_z_accelerometer\"] = data3[\"z_accelerometer_fil\"].rolling(8, min_periods=1).median()\n",
    "\n",
    "data4[\"median_window_x_accelerometer\"] = data4[\"x_accelerometer_fil\"].rolling(8, min_periods=1).median()\n",
    "data4[\"median_window_y_accelerometer\"] = data4[\"y_accelerometer_fil\"].rolling(8, min_periods=1).median()\n",
    "data4[\"median_window_z_accelerometer\"] = data4[\"z_accelerometer_fil\"].rolling(8, min_periods=1).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll_column_with_duplicate(column):\n",
    "    result = np.roll(column, 1)\n",
    "    result[0] = result[1]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[\"tendency_window_x_accelerometer\"] = roll_column_with_duplicate(data1[\"mean_window_x_accelerometer\"].values) / data1[\"mean_window_x_accelerometer\"]\n",
    "data1[\"tendency_window_y_accelerometer\"] = roll_column_with_duplicate(data1[\"mean_window_y_accelerometer\"].values) / data1[\"mean_window_y_accelerometer\"]\n",
    "data1[\"tendency_window_z_accelerometer\"] = roll_column_with_duplicate(data1[\"mean_window_z_accelerometer\"].values) / data1[\"mean_window_z_accelerometer\"]\n",
    "\n",
    "data2[\"tendency_window_x_accelerometer\"] = roll_column_with_duplicate(data2[\"mean_window_x_accelerometer\"].values) / data2[\"mean_window_x_accelerometer\"]\n",
    "data2[\"tendency_window_y_accelerometer\"] = roll_column_with_duplicate(data2[\"mean_window_y_accelerometer\"].values) / data2[\"mean_window_y_accelerometer\"]\n",
    "data2[\"tendency_window_z_accelerometer\"] = roll_column_with_duplicate(data2[\"mean_window_z_accelerometer\"].values) / data2[\"mean_window_z_accelerometer\"]\n",
    "\n",
    "data3[\"tendency_window_x_accelerometer\"] = roll_column_with_duplicate(data3[\"mean_window_x_accelerometer\"].values) / data3[\"mean_window_x_accelerometer\"]\n",
    "data3[\"tendency_window_y_accelerometer\"] = roll_column_with_duplicate(data3[\"mean_window_y_accelerometer\"].values) / data3[\"mean_window_y_accelerometer\"]\n",
    "data3[\"tendency_window_z_accelerometer\"] = roll_column_with_duplicate(data3[\"mean_window_z_accelerometer\"].values) / data3[\"mean_window_z_accelerometer\"]\n",
    "\n",
    "data4[\"tendency_window_x_accelerometer\"] = roll_column_with_duplicate(data4[\"mean_window_x_accelerometer\"].values) / data4[\"mean_window_x_accelerometer\"]\n",
    "data4[\"tendency_window_y_accelerometer\"] = roll_column_with_duplicate(data4[\"mean_window_y_accelerometer\"].values) / data4[\"mean_window_y_accelerometer\"]\n",
    "data4[\"tendency_window_z_accelerometer\"] = roll_column_with_duplicate(data4[\"mean_window_z_accelerometer\"].values) / data4[\"mean_window_z_accelerometer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for storing parts of dataframe by its event\n",
    "event_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dict = add_events_to_dict(data1, event_dict)\n",
    "event_dict = add_events_to_dict(data2, event_dict)\n",
    "event_dict = add_events_to_dict(data3, event_dict)\n",
    "event_dict = add_events_to_dict(data4, event_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agg_br = pd.concat(event_dict[\"Aggressive breaking\"][:9])\n",
    "val_agg_br = pd.concat(event_dict[\"Aggressive breaking\"][9:])\n",
    "\n",
    "train_agg_ac = pd.concat(event_dict[\"Aggressive acceleration\"][:9])\n",
    "val_agg_ac = pd.concat(event_dict[\"Aggressive acceleration\"][9:])\n",
    "\n",
    "train_agg_lt = pd.concat(event_dict[\"Aggressive left turn\"][:9])\n",
    "val_agg_lt = pd.concat(event_dict[\"Aggressive left turn\"][9:])\n",
    "\n",
    "train_agg_rt = pd.concat(event_dict[\"Aggressive right turn\"][:9])\n",
    "val_agg_rt = pd.concat(event_dict[\"Aggressive right turn\"][9:])\n",
    "\n",
    "train_agg_lc = pd.concat(event_dict[\"Aggressive left lane change\"][:3])\n",
    "val_agg_lc = pd.concat(event_dict[\"Aggressive left lane change\"][3:])\n",
    "\n",
    "train_agg_rc = pd.concat(event_dict[\"Aggressive right lane change\"][:3])\n",
    "val_agg_rc = pd.concat(event_dict[\"Aggressive right lane change\"][3:])\n",
    "\n",
    "train_agg_rc = pd.concat(event_dict[\"Non-aggressive event\"][:11])\n",
    "val_agg_rc = pd.concat(event_dict[\"Non-aggressive event\"][11:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train_agg_br, train_agg_ac, train_agg_lt, train_agg_rt, train_agg_lc, train_agg_rc, train_agg_rc])\n",
    "val = pd.concat([val_agg_br, val_agg_ac, val_agg_lt, val_agg_rt, val_agg_lc, val_agg_rc, val_agg_rc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_save = [\"mean_window_x_accelerometer\",\n",
    "                 \"mean_window_y_accelerometer\",\n",
    "                 \"mean_window_z_accelerometer\",\n",
    "                 \"std_window_x_accelerometer\",\n",
    "                 \"std_window_y_accelerometer\",\n",
    "                 \"std_window_z_accelerometer\",\n",
    "                 \"median_window_x_accelerometer\",\n",
    "                 \"median_window_y_accelerometer\",\n",
    "                 \"median_window_z_accelerometer\",\n",
    "                 \"tendency_window_x_accelerometer\",\n",
    "                 \"tendency_window_y_accelerometer\",\n",
    "                 \"tendency_window_z_accelerometer\",\n",
    "                 \"event\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(method=\"bfill\")\n",
    "val = val.fillna(method=\"bfill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = shuffle(train)\n",
    "val = shuffle(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[columns_to_save].to_csv('data/train_accelerometer_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val[columns_to_save].to_csv('data/val_accelerometer_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
